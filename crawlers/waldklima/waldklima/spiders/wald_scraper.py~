import scrapy


class WaldScraperSpider(scrapy.Spider):
    name = "wald_scraper"
    allowed_domains = ["www.waldklimafonds.de"]
    start_urls = ["https://www.waldklimafonds.de/projekte/projektdatenbank"]
    quotechar = "'"

    def parse(self, response):
        # get projects
        projects = response.css("a.details-link::attr(href)").getall()

        for project in projects:
            req = scrapy.Request(response.urljoin(project), callback=self.sub_parse)
            yield req

    def sub_parse(self, response):
        project_name = response.css(".large-9 > div:nth-child(4) > h2:nth-child(1)::text").get()
        program_partner = response.css("div.detail:nth-child(1) > div:nth-child(2)::text").getall()
        project_id = response.css("div.detail:nth-child(3) > div:nth-child(2)::text").getall()
        project_start = response.css("div.detail:nth-child(4) > div:nth-child(2)::text").get()
        project_end = response.css("div.detail:nth-child(5) > div:nth-child(2)::text").get()
        descrition = response.css("div.detail:nth-child(6) > div:nth-child(2)::text").getall()

        yield {
            "name": project_name,
            "type": "Projekt",
            "program": "waldklimafonds",
            "Einrichtung": program_partner,
            "FÃ¶rderkennzeichen": project_id,
            "Beginn": project_start,
            "Ende": project_end,
            "Beschreibung": descrition
            }
